{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <u>Deepfake Video Detection Project</u>"
      ],
      "metadata": {
        "id": "P161S7VdyUZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2KX3VLh3ek9r"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2 as cv\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MetaData of the DataSet\n"
      ],
      "metadata": {
        "id": "qxfjV1sYN4JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_metadata = pd.read_json('/content/drive/MyDrive/Dataset/train_sample_videos/metadata.json').T\n",
        "train_sample_metadata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "tl4xg0yTfxtH",
        "outputId": "adb3f040-1e2f-49e4-fad9-0c3b44213adc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "File /content/drive/MyDrive/Dataset/train_sample_videos/metadata.json does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-12a1ec13461b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_sample_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Dataset/train_sample_videos/metadata.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_sample_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mconvert_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     json_reader = JsonReader(\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ujson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         ):\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {filepath_or_buffer} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File /content/drive/MyDrive/Dataset/train_sample_videos/metadata.json does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Index is the Name of the Video\n",
        "- Label represents the type of video it is.\n",
        " - if the label is Fake orginal column contains its orginal video name else it is None\n"
      ],
      "metadata": {
        "id": "LsSPZAmEOWKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_metadata.info()"
      ],
      "metadata": {
        "id": "yiW2t3sPA7uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_metadata['label'].value_counts()"
      ],
      "metadata": {
        "id": "SrAzrEHlBBDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_metadata.groupby('label')['label'].count().plot(figsize=(10, 5), kind='bar', title='Distribution of Labels in the Training Set')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FJduZPxwB7wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unique Values"
      ],
      "metadata": {
        "id": "d6hnkX9tVEwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_values(data):\n",
        "    total = data.count()\n",
        "    tt = pd.DataFrame(total)\n",
        "    tt.columns = ['Total']\n",
        "    uniques = []\n",
        "    for col in data.columns:\n",
        "        unique = data[col].nunique()\n",
        "        uniques.append(unique)\n",
        "    tt['Uniques'] = uniques\n",
        "    return(np.transpose(tt))"
      ],
      "metadata": {
        "id": "-V1PIsK0VEWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values(train_sample_metadata)"
      ],
      "metadata": {
        "id": "3EYDFLg4VQmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Uniquess of label =2 tells that there are 2 unique values(\"FAKE\", \"REAL\" )\n",
        "- Uniquess of original =209 tells that there are 209 unique video names in the train_sample_metadata dataframe"
      ],
      "metadata": {
        "id": "TLmoZkAuVaLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Most Frequent items"
      ],
      "metadata": {
        "id": "CZ53lWlhWUct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_frequent_values(data):\n",
        "    total = data.count()\n",
        "    tt = pd.DataFrame(total)\n",
        "    tt.columns = ['Total']\n",
        "    items = []\n",
        "    vals = []\n",
        "    for col in data.columns:\n",
        "        itm = data[col].value_counts().index[0]\n",
        "        val = data[col].value_counts().values[0]\n",
        "        items.append(itm)\n",
        "        vals.append(val)\n",
        "    tt['Most frequent item'] = items\n",
        "    tt['Frequency'] = vals\n",
        "    tt['Percent from total'] = np.round(vals / total * 100, 3)\n",
        "    return(np.transpose(tt))\n"
      ],
      "metadata": {
        "id": "q3MYSwpAWTsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_frequent_values(train_sample_metadata)"
      ],
      "metadata": {
        "id": "z-Txx_fiWbp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- FAKE label is the most frequently occuring item in label column with percentage of 80.75%\n",
        "- which indicates REAL label is occuring with percentage of 19.25%\n",
        "- atvmxvwyns.mp4 is the most frequently occuring video"
      ],
      "metadata": {
        "id": "VCtY8OLdWjYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_counts = pd.DataFrame(train_sample_metadata['original'].value_counts())\n",
        "original_counts.head(10)"
      ],
      "metadata": {
        "id": "lMZiJUx6a_La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### some of the Fake Video names"
      ],
      "metadata": {
        "id": "kH-II0GYXguc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='FAKE'].sample(10).index)\n",
        "fake_train_sample_video"
      ],
      "metadata": {
        "id": "XyWuSEl5Xkvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### some of the REAL Video names"
      ],
      "metadata": {
        "id": "OLLs4e4MXwXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='REAL'].sample(10).index)    # returning the index value which is video name\n",
        "real_train_sample_video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "b4lyMConX1j9",
        "outputId": "07430ce3-a601-44fc-8040-c07db598df3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_sample_metadata' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a2033839a9a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreal_train_sample_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sample_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_sample_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'REAL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# returning the index value which is video name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreal_train_sample_video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_sample_metadata' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to display the image from the video"
      ],
      "metadata": {
        "id": "f6MRz9rwPjt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image_from_video(video_path):\n",
        "    '''\n",
        "    input: video_path - path for video\n",
        "    process:\n",
        "    1. perform a video capture from the video\n",
        "    2. read the image\n",
        "    3. display the image\n",
        "    '''\n",
        "    capture_image = cv.VideoCapture(video_path)\n",
        "    ret, frame = capture_image.read()\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)   # converting the frame color to RGB\n",
        "    ax.imshow(frame)\n",
        ""
      ],
      "metadata": {
        "id": "oQsFrycVgQJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fake Video Images"
      ],
      "metadata": {
        "id": "-RQLclNDZ65M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for video in fake_train_sample_video:\n",
        "  display_image_from_video(os.path.join(\"/content/drive/MyDrive/Dataset/train_sample_videos/\"+video))\n",
        "  print()\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "ZOmAQ4_fg2tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REAL Video Images"
      ],
      "metadata": {
        "id": "WT0mhUQZaHLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for video in real_train_sample_video:\n",
        "  display_image_from_video(os.path.join(\"/content/drive/MyDrive/Dataset/train_sample_videos/\"+video))\n",
        "  print()\n",
        "  print()"
      ],
      "metadata": {
        "id": "cz49JGlzaKGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to play the video"
      ],
      "metadata": {
        "id": "KTFdBQRMQASF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def play_video(video_file):\n",
        "    '''\n",
        "    Display video\n",
        "    param: video_file - the name of the video file to display\n",
        "    param: subset - the folder where the video file is located (can be TRAIN_SAMPLE_FOLDER or TEST_Folder)\n",
        "    '''\n",
        "    video_url = open(video_file,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(video_url).decode()\n",
        "    return HTML(\"\"\"<video width=500 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "Fo5XlXwphbL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_video(\"/content/drive/MyDrive/Dataset/train_sample_videos/aapnvogymq.mp4\")"
      ],
      "metadata": {
        "id": "luo9dydXjHWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Video in a Darkness"
      ],
      "metadata": {
        "id": "65v7maMEb3Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "play_video(\"/content/drive/MyDrive/Dataset/train_sample_videos/atvmxvwyns.mp4\")"
      ],
      "metadata": {
        "id": "KTbrkWNdjVY8",
        "outputId": "ed35aaea-9272-4f7e-cb29-227bef5f5bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'play_video' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a0d51f165b82>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Dataset/train_sample_videos/atvmxvwyns.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'play_video' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding Average Frame rate of Videos"
      ],
      "metadata": {
        "id": "bBBmPouy-NU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "videos = glob.glob('/content/drive/MyDrive/Dataset/train_sample_videos/*.mp4')\n",
        "frame_cnt = []\n",
        "for video in videos:\n",
        "  capture = cv.VideoCapture(video)\n",
        "  frame_cnt.append(int(capture.get(cv.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"Frames: \",frame_cnt)\n",
        "print(\"Avg Frame per video: \",np.mean(frame_cnt))"
      ],
      "metadata": {
        "id": "3lfz5-ku2YCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RgaDIBYdCWFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Locating a Face within an Image"
      ],
      "metadata": {
        "id": "bRCiJ1dFCQt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition"
      ],
      "metadata": {
        "id": "M1Fcl-Lt8TZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_from_video(video_path):\n",
        "    '''\n",
        "    input: video_path - path for video\n",
        "    process:\n",
        "    1. perform a video capture from the video\n",
        "    2. read the image\n",
        "    3. display the image\n",
        "    '''\n",
        "    capture_image = cv.VideoCapture(video_path)\n",
        "    ret, frame = capture_image.read()\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)   # converting the frame color to RGB\n",
        "    ax.imshow(frame)\n",
        "\n",
        "    return frame"
      ],
      "metadata": {
        "id": "XEs6G9KzDIV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = image_from_video(\"/content/drive/MyDrive/Dataset/train_sample_videos/aagfhgtpmv.mp4\")"
      ],
      "metadata": {
        "id": "uJ7ycaJnFVw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition"
      ],
      "metadata": {
        "id": "VVj6BJhfGC81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_locations = face_recognition.face_locations(image)\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "for face_location in face_locations:\n",
        "\n",
        "  top,right,bottom,left = face_location\n",
        "  print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
        "\n",
        "  face_image = image[top:bottom, left:right]\n",
        "  fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
        "  plt.grid(False)\n",
        "  ax.xaxis.set_visible(False)\n",
        "  ax.yaxis.set_visible(False)\n",
        "  ax.imshow(face_image)\n"
      ],
      "metadata": {
        "id": "YZIloLFtCfYe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}